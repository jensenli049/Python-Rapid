{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e95c9441",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f215e168",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31dd4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import opencv\n",
    "import cv2 as cv\n",
    "# import math functions\n",
    "import math\n",
    "from math import dist\n",
    "import numpy as np\n",
    "# import system libraries\n",
    "import glob\n",
    "import os\n",
    "# import distance calculation libraries\n",
    "import imutils\n",
    "from imutils import perspective\n",
    "# import data processing libraries\n",
    "import pandas\n",
    "# import pytorch\n",
    "import torch\n",
    "# import socket\n",
    "from ast import Break\n",
    "import imp\n",
    "from multiprocessing.connection import answer_challenge, wait\n",
    "import socket\n",
    "import time\n",
    "# import machine learning model configs\n",
    "from distutils.version import LooseVersion\n",
    "import mmcv\n",
    "from mmcv import Config\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmrotate.datasets.builder import ROTATED_DATASETS\n",
    "from mmrotate.datasets.mvtec import ScrewsDataset\n",
    "from mmdet.apis import inference_detector, show_result_pyplot, set_random_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d18cb40",
   "metadata": {},
   "source": [
    "## 2. Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbb28c5",
   "metadata": {},
   "source": [
    "#### Function to find contours of an image:\n",
    "*Takes a file path as input and returns contours*  \n",
    "\n",
    "Contour resource: https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html  \n",
    "Otsu Thresholding: https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0432d846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contours_auto(image):\n",
    "    # convert image to grayscale\n",
    "    imgray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    # threshold image with otsu thresholding\n",
    "    blur = cv.GaussianBlur(imgray,(5,5),0)\n",
    "    ret,thr = cv.threshold(blur, 120, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "    \n",
    "    # find contours\n",
    "    # tree = all contours\n",
    "    contours_tree, hierarchy = cv.findContours(thr, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    # external = only extreme outer contours (used for orientation)\n",
    "    contours_ext, hierarchy = cv.findContours(thr, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    contours_main = []\n",
    "    for c in contours_tree:\n",
    "        # Calculate the area of each contour\n",
    "        area = cv.contourArea(c)\n",
    "\n",
    "        # Ignore contours that are too small or too large\n",
    "        if area > 5000 and 100000 > area:\n",
    "            contours_main.append(c)\n",
    "    \"\"\"      \n",
    "    result = image.copy()\n",
    "    cv.drawContours(result, contours_main, -1, (0, 0, 255), 2)\n",
    "    cv.imshow('Output Image', result)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "    \"\"\"\n",
    "    return contours_main, contours_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc130ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contours_man(image, min_t, max_t, min_a, max_a):\n",
    "    # convert image to grayscale\n",
    "    imgray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    # manual threshold\n",
    "    blur = cv.GaussianBlur(imgray,(5,5),0)\n",
    "    ret,thr = cv.threshold(blur, min_t, max_t, cv.THRESH_BINARY)\n",
    "    # find contours\n",
    "    # tree = all contours\n",
    "    contours_tree, hierarchy = cv.findContours(thr, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    # external = only extreme outer contours (used for orientation)\n",
    "    contours_ext, hierarchy = cv.findContours(thr, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    contours_t = []\n",
    "    contours_e = []\n",
    "    for t,e in zip(contours_tree, contours_ext):\n",
    "        # Calculate the area of each contour\n",
    "        areaT = cv.contourArea(t)\n",
    "        areaE = cv.contourArea(e)\n",
    "\n",
    "        # Ignore contours that are too small or too large\n",
    "        if areaT > min_a and max_a > areaT:\n",
    "            contours_t.append(t)\n",
    "        if areaE > min_a and max_a > areaE:\n",
    "            contours_e.append(e)\n",
    "\n",
    "    return contours_t, contours_e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b3c73",
   "metadata": {},
   "source": [
    "#### Finding centroid of object:\n",
    "*Takes a list of contours and returns the centroid for each through moments*  \n",
    "\n",
    "Code base from https://docs.opencv.org/4.x/dd/d49/tutorial_py_contour_features.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0314b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centroids(contours):\n",
    "    # instantiate two empty lists\n",
    "    cX, cY = [], []\n",
    "    for c in contours:\n",
    "        # calculate moments for each contour\n",
    "        M = cv.moments(c)\n",
    "        # avoid divide by zero error\n",
    "        if M[\"m00\"] == 0:\n",
    "            return 0, 0\n",
    "        # calculate x,y coordinate of center\n",
    "        cX.append(int(M[\"m10\"] / M[\"m00\"]))\n",
    "        cY.append(int(M[\"m01\"] / M[\"m00\"]))\n",
    "        \"\"\"\n",
    "        result = img.copy()\n",
    "        cv.drawContours(result, contours, -1, (0, 0, 255), 2)\n",
    "        cv.circle(img, (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"])), 5, (0, 0, 0), -1)\n",
    "        cv.imshow('Output Image', result)\n",
    "        cv.waitKey(0)\n",
    "        cv.destroyAllWindows()\n",
    "        \"\"\"\n",
    "        \n",
    "    return cX, cY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ed2af4",
   "metadata": {},
   "source": [
    "#### Calculate the orientation of an image through a rotated box:\n",
    "\n",
    "\n",
    "Code based from: https://stackoverflow.com/questions/58632469/how-to-find-the-orientation-of-an-object-shape-python-opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0fedfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_orientation(contours): \n",
    "    # instantiate an empty list\n",
    "    angles = []\n",
    "    for c in contours:\n",
    "        # calculate bounding box with minimum area, considers rotation\n",
    "        rect = cv.minAreaRect(c)\n",
    "        box = cv.boxPoints(rect)\n",
    "        \n",
    "        # calculate rotation angle\n",
    "        angle = rect[-1]\n",
    "        if angle > 45:\n",
    "            angle = 90 - angle\n",
    "        else:\n",
    "            angle = -angle\n",
    "        angles.append(int(angle))\n",
    "        \"\"\"\n",
    "        result = img.copy()\n",
    "        box = np.int0(box)\n",
    "        cv.drawContours(result,[box],0,(0,0,255),2)\n",
    "        cv.imshow(\"RESULT\", result)\n",
    "        cv.waitKey(0)\n",
    "        cv.destroyAllWindows()\n",
    "        \"\"\"\n",
    "    return angles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48967dcd",
   "metadata": {},
   "source": [
    "#### Calculate dimension of objects using a bounding box:  \n",
    "Code Reference: https://pyimagesearch.com/2016/03/28/measuring-size-of-objects-in-an-image-with-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b446a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def midpoint(ptA, ptB): # used for calculating distances\n",
    "    return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)\n",
    "\n",
    "def calculate_dists(image, width, contours):\n",
    "    # sort contours smallest to largest\n",
    "    sorted_contours = sorted(contours, key=cv.contourArea, reverse=False)\n",
    "    pixelsPerMetric = None\n",
    "    \n",
    "    for cnt in sorted_contours:\n",
    "        result = image.copy()\n",
    "        box = cv.minAreaRect(cnt)\n",
    "        box = cv.boxPoints(box)\n",
    "        box = np.array(box, dtype=\"int\")\n",
    "        box = perspective.order_points(box)\n",
    "        \n",
    "        # calculate dimensions of object\n",
    "        (tl, tr, br, bl) = box # indicates corners of bounding box\n",
    "        mtlr = midpoint(tl, tr)\n",
    "        mblr = midpoint(bl, br)\n",
    "        mtll = midpoint(tl, bl)\n",
    "        mbrr = midpoint(tr, br)\n",
    "        center = midpoint(mtlr,mblr)\n",
    "\n",
    "        # compute the Euclidean distance between the midpoints\n",
    "        dA = np.linalg.norm(np.array(mtlr)-np.array(mblr))\n",
    "        dB = np.linalg.norm(np.array(mtll)-np.array(mbrr))\n",
    "\n",
    "        # compute the size of the object using given metric\n",
    "        if pixelsPerMetric is None:\n",
    "            pixelsPerMetric = dB / width\n",
    "\n",
    "        hght = dA / pixelsPerMetric\n",
    "        wdth = dB / pixelsPerMetric\n",
    "\n",
    "        cv.putText(image, \"{:.2f}x{:.2f}in\".format(hght, wdth), \n",
    "                    (int(center[0] - 35), int(center[1] - 10)), \n",
    "                    cv.FONT_HERSHEY_SIMPLEX, 0.35, (218, 198, 38), 1)\n",
    "        \"\"\"\n",
    "        box = np.int0(box)\n",
    "        cv.drawContours(result,[box],0,(0,0,255),2)\n",
    "        cv.imshow(\"RESULT\", result)\n",
    "        cv.waitKey(0)\n",
    "        cv.destroyAllWindows()\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6c4d83",
   "metadata": {},
   "source": [
    "#### Functions to draw contours, centroids, and orientation axes on an image:\n",
    "*Takes an image, a contours list, orientation, and centroid coordinates and returns an image with the added features*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee0d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_contours(image, contours):\n",
    "    # draw contours\n",
    "    for c in contours:\n",
    "        cv.drawContours(image, contours, -1, (0, 0, 255), 2)\n",
    "        \n",
    "def draw_orientation(image, angles, cX, cY):\n",
    "    for i, (a, x, y) in enumerate(zip(angles, cX, cY)):\n",
    "        # draw centroid\n",
    "        cv.circle(image, (x, y), 3, (0, 0, 0), -1)\n",
    "        # calculate orientation axes\n",
    "        hypotenuse = 100\n",
    "        x_axisX = int(x+hypotenuse*math.cos(math.radians(a)))\n",
    "        x_axisY = int(y-hypotenuse*math.sin(math.radians(a)))\n",
    "        y_axisX = int(x-hypotenuse*math.sin(math.radians(a)))\n",
    "        y_axisY = int(y-hypotenuse*math.cos(math.radians(a)))\n",
    "        # draw axes\n",
    "        cv.line(image, (x, y), (x_axisX, x_axisY), (127,255,0), 2)\n",
    "        cv.line(image, (x, y), (y_axisX, y_axisY), (255,255,224), 2)\n",
    "\n",
    "def draw_all(image, contours, angles, cX, cY):\n",
    "    result =  image.copy()\n",
    "    draw_contours(result, contours)\n",
    "    draw_orientation(result, angles, cX, cY)\n",
    "    cv.imshow('Output Image', result)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "def draw_features(image, contours, angles, cX, cY):\n",
    "    # Make a copy of the image to draw on\n",
    "    result =  image.copy()\n",
    "    for i, (c, a, x, y) in enumerate(zip(contours, angles, cX, cY)):\n",
    "        # draw contours\n",
    "        cv.drawContours(result, contours, -1, (0, 0, 255), 2)\n",
    "        # draw centroid\n",
    "        cv.circle(result, (x, y), 3, (0, 0, 0), -1)\n",
    "        # calculate orientation axes (use complex numbers functions to simplify)\n",
    "        hypotenuse = 100\n",
    "        x_axisX = int(x+hypotenuse*math.cos(math.radians(a)))\n",
    "        x_axisY = int(y-hypotenuse*math.sin(math.radians(a)))\n",
    "        y_axisX = int(x-hypotenuse*math.sin(math.radians(a)))\n",
    "        y_axisY = int(y-hypotenuse*math.cos(math.radians(a)))\n",
    "        cv.putText(result, \"{:.1f}deg\".format(a), \n",
    "                    (int(x - 35), int(y + 10)), \n",
    "                    cv.FONT_HERSHEY_SIMPLEX, 0.35, (218, 198, 38), 1)\n",
    "        # draw axes\n",
    "        cv.line(result, (x, y), (x_axisX, x_axisY), (127,255,0), 2)\n",
    "        cv.line(result, (x, y), (y_axisX, y_axisY), (255,255,224), 2)\n",
    "    cv.imshow('Output Image', result)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac49c93a",
   "metadata": {},
   "source": [
    "#### Miscallaneous Functions\n",
    "*Nothing function is a dummy function for creating trackbars/number sliders*  \n",
    "Trackbar code from: https://blog.electroica.com/trackbar-in-opencv-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023dacc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nothing(x): #dummy function for trackbar\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61707b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_folder(folder_name): #makes new directory if it does not already exist\n",
    "    path = os.path.join(os.getcwd(), folder_name)\n",
    "    print(path)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fcfc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_images(folder_name, image_start): #removes all specified images from folder\n",
    "    path = os.path.join(os.getcwd(), folder_name)\n",
    "    for fname in os.listdir(path):\n",
    "        if fname.startswith(image_start):\n",
    "            os.remove(os.path.join(path,fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c86ac0",
   "metadata": {},
   "source": [
    "## Section 3. Calibrate Camera  \n",
    "Webcam code reference: https://stackoverflow.com/questions/34588464/python-how-to-capture-image-from-webcam-on-click-using-opencv  \n",
    "Calibration code reference: https://learnopencv.com/camera-calibration-using-opencv/  \n",
    "Opencv Calibration doc: https://docs.opencv.org/3.4/dc/dbb/tutorial_py_calibration.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc5bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_webcam_pics(num, folder_name):\n",
    "    check_folder(folder_name)\n",
    "    #clear_images(folder_name, \"calibration_pic\")\n",
    "    \n",
    "    webcamVideo = cv.VideoCapture(0)\n",
    "    cv.namedWindow(\"webcam\") # used to display camera feed\n",
    "    \n",
    "    print(\"press space to save an image\")\n",
    "    while num >= 1:\n",
    "        ret, frame = webcamVideo.read()\n",
    "        if not ret: # check if camera is working\n",
    "            print(\"Camera off\")\n",
    "            break\n",
    "            \n",
    "        cv.imshow(\"feed\", frame) # display camera feed\n",
    "         \n",
    "        k = cv.waitKey(1) & 0xFF #gets value of key pressed\n",
    "        if k == 27: # esc key pressed\n",
    "            print(\"Escape hit, closing...\")\n",
    "            break\n",
    "        elif k == 32: # space key pressed\n",
    "            image_path = os.path.join(os.getcwd(), folder_name, \"calibration_pic_{}.jpg\".format(num))\n",
    "            cv.imwrite(image_path, frame)            \n",
    "            print(\"saving image\")\n",
    "            num -= 1\n",
    "    webcamVideo.release()\n",
    "    cv.destroyAllWindows()      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd917fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cam_cal(newpics = False): # determine if new cals are needed\n",
    "    # Defining the dimensions of checkerboard\n",
    "    CHECKERBOARD = (7,10) # checkerboard needs to be large enough to load\n",
    "    criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "    \n",
    "    # Creating vector to store vectors of 3D points for each checkerboard image\n",
    "    objpoints = [] \n",
    "    # Creating vector to store vectors of 2D points for each checkerboard image\n",
    "    imgpoints = [] \n",
    "\n",
    "    # Defining the world coordinates for 3D points\n",
    "    objp = np.zeros((CHECKERBOARD[0] * CHECKERBOARD[1], 3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:CHECKERBOARD[0], 0:CHECKERBOARD[1]].T.reshape(-1, 2)\n",
    "    prev_img_shape = None\n",
    "\n",
    "    # Extracting path of individual image stored in a given directory\n",
    "    if(newpics): #\n",
    "        take_webcam_pics(20, \"calibs\") #Take 20 pictures for calibration\n",
    "    images = glob.glob('./calibs/*.jpg')\n",
    "    for fname in images:\n",
    "        img = cv.imread(fname)\n",
    "        gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "        # Find the chess board corners\n",
    "        # If desired number of corners are found in the image then ret = true\n",
    "        ret, corners = cv.findChessboardCorners(gray, CHECKERBOARD, \n",
    "            cv.CALIB_CB_ADAPTIVE_THRESH + cv.CALIB_CB_FAST_CHECK + cv.CALIB_CB_NORMALIZE_IMAGE)\n",
    "        \"\"\"\n",
    "        If desired number of corner are detected,\n",
    "        we refine the pixel coordinates and display them on the images of checker board\n",
    "        \"\"\"\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            # refining pixel coordinates for given 2d points.\n",
    "            corners2 = cv.cornerSubPix(gray, corners, (11,11),(-1,-1), criteria)\n",
    "            imgpoints.append(corners2)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            #img = cv.drawChessboardCorners(img, CHECKERBOARD, corners2, ret)\n",
    "\n",
    "        #cv.imshow('img',img) # show images\n",
    "        #cv.waitKey(0)\n",
    "\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "    h,w = img.shape[:2]\n",
    "\n",
    "    \"\"\"\n",
    "    Performing camera calibration by passing the value of known 3D points (objpoints)\n",
    "    and corresponding pixel coordinates of the detected corners (imgpoints)\n",
    "    \"\"\"\n",
    "    ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    # print calibration values\n",
    "    \"\"\"\n",
    "    print(\"Camera matrix : \\n\")\n",
    "    print(mtx)\n",
    "    print(\"dist : \\n\")\n",
    "    print(dist)\n",
    "    print(\"rvecs : \\n\")\n",
    "    print(rvecs)\n",
    "    print(\"tvecs : \\n\")\n",
    "    print(tvecs)\n",
    "    \"\"\"\n",
    "    return ret, mtx, dist, rvecs, tvecs # return calibration values for future images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c214322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort_img(img, mtx, dist):\n",
    "    #img = cv.imread(img)\n",
    "    h, w = img.shape[:2]\n",
    "    newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "    \n",
    "    # undistort\n",
    "    dst = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    "    # crop the image\n",
    "    x, y, w, h = roi\n",
    "    dst = dst[y:y+h, x:x+w]\n",
    "    #cv.imwrite('calibresult.png', dst)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a441b55b",
   "metadata": {},
   "source": [
    "## Section 4. Coordinate System Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4fd640",
   "metadata": {},
   "source": [
    "Define Coordinate System from the *top right corner* of the *leftmost object*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e75c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bottom_contour(contours):\n",
    "    sorted_contours = sorted(contours, key=lambda contours: cv.boundingRect(contours)[1], reverse=False) # sort left-to-right\n",
    "    leftmost = []\n",
    "    remainder = []\n",
    "    for ind, cnt in enumerate(sorted_contours):\n",
    "        if ind == 0:\n",
    "            leftmost = cnt\n",
    "        else:\n",
    "            remainder.append(cnt)\n",
    "    return leftmost, remainder\n",
    "    \n",
    "def draw_axes(imagedraw, origin, mtx, dist):\n",
    "    CHECKERBOARD = (7,10)\n",
    "    criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "    objp = np.zeros((CHECKERBOARD[0]*CHECKERBOARD[1],3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:CHECKERBOARD[0],0:CHECKERBOARD[1]].T.reshape(-1,2)\n",
    "    axis = np.float32([[10,0,0], [0,10,0], [0,0,-10]]).reshape(-1,3)\n",
    "    \n",
    "    img = cv.imread(\"./calibs/calibration_pic_1.jpg\")\n",
    "    gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv.findChessboardCorners(gray, CHECKERBOARD, None)\n",
    "    if ret == True:\n",
    "        corners2 = cv.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n",
    "        # Find the rotation and translation vectors.\n",
    "        ret, rvecs, tvecs = cv.solvePnP(objp, corners2, mtx, dist)\n",
    "        # project 3D points to image plane\n",
    "        imgpts, jac = cv.projectPoints(axis, rvecs, tvecs, mtx, dist)\n",
    "        #print(origin)\n",
    "        #print(imgpts[0].ravel(), imgpts[1].ravel(), imgpts[2].ravel())\n",
    "        # draw x,y,z axes from origin (leftmost centroid contour)\n",
    "        imagedraw = cv.line(imagedraw, origin, (int(imgpts[0].ravel()[0]), int(imgpts[0].ravel()[1])), (255,0,0), 5)\n",
    "        imagedraw = cv.line(imagedraw, origin, (int(imgpts[1].ravel()[0]), int(imgpts[1].ravel()[1])), (0,255,0), 5)\n",
    "        imagedraw = cv.line(imagedraw, origin, (int(imgpts[2].ravel()[0]), int(imgpts[2].ravel()[1])), (0,0,255), 5)\n",
    "\n",
    "    return imagedraw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c471d1",
   "metadata": {},
   "source": [
    "## Section 6. Main  Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c572fbc2",
   "metadata": {},
   "source": [
    "Mainly used for single image orientation and position detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2982c286",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_type = 0 # image: 0 | webcam: 1\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cam_cal(False) # calibrate camera\n",
    "print(\"Clearing active_pics\")\n",
    "clear_images(os.getcwd(), \"active_pic\") # clear old active pics\n",
    "image_num = 1\n",
    "\n",
    "# create a seperate window named 'controls' for trackbar\n",
    "cv.namedWindow('controls', cv.WINDOW_NORMAL)\n",
    "# create trackbars in 'controls' window\n",
    "cv.createTrackbar('Min Thresh','controls',0,255,nothing)\n",
    "cv.createTrackbar('Max Thresh','controls',255,255,nothing)\n",
    "cv.createTrackbar('Min Area','controls',2000,10000,nothing)\n",
    "cv.createTrackbar('Max Area','controls',1000000,200000,nothing)\n",
    "\n",
    "# Start active video capture\n",
    "#webcamVideo = cv.VideoCapture('Presentation1.mp4')\n",
    "#cv.namedWindow(\"webcam\") # used to display camera feed\n",
    "\n",
    "print(\"press space to save an image\")\n",
    "while True:\n",
    "    if display_type == 1: # webcam active capture\n",
    "        ret, frame = webcamVideo.read()\n",
    "        undist_frame = undistort_img(frame, mtx, dist) # apply camera calibration\n",
    "        imgcopy = undist_frame.copy()\n",
    "        if not ret: # check if camera is working\n",
    "            print(\"Camera off\")\n",
    "            break\n",
    "    if display_type == 0: # static image capture\n",
    "        #print(os.getcwd())\n",
    "        #img = cv.imread(\"screws_198.png\")\n",
    "        img = cv.imread(\"input_img.jpg\") #image2.png\n",
    "        #print('Original Dimensions : ',img.shape)\n",
    "        #img = cv.resize(img, (int(img.shape[1]*0.3), int(img.shape[0]*0.3)), cv.INTER_AREA)\n",
    "        #cntrs_t, cntrs_e = find_contours_auto(img) # auto-generated contours values --> will be changed\n",
    "        imgcopy = img.copy()\n",
    "    \n",
    "        \n",
    "    # get Trackbar values\n",
    "    min_thres = int(cv.getTrackbarPos('Min Thresh','controls'))\n",
    "    max_thres = int(cv.getTrackbarPos('Max Thresh','controls'))\n",
    "    area_min = int(cv.getTrackbarPos('Min Area','controls'))\n",
    "    area_max = int(cv.getTrackbarPos('Max Area','controls'))\n",
    "    \n",
    "    # calculate contours\n",
    "    #cntrs_t, cntrs_e = find_contours_auto(imgcopy)\n",
    "    cntrs_t, cntrs_e = find_contours_man(imgcopy, min_thres, max_thres, area_min, area_max)\n",
    "    leftmost, cntrs_t = find_bottom_contour(cntrs_t) # pops left most contour from list for axes\n",
    "    _, cntrs_e = find_bottom_contour(cntrs_e) # shorten cntrs_e as well\n",
    "    draw_contours(imgcopy, cntrs_t)\n",
    "        \n",
    "    #cv.imshow(\"orig_feed\", frame) # display camera feed\n",
    "    #imgcopy = draw_axes(imgcopy, tuple(find_centroids(leftmost)), mtx, dist) # draw axes using leftmost contour and calibration plane\n",
    "    cv.imshow(\"undist_feed\", imgcopy) # display undistorted camera feed\n",
    "    \n",
    "    k = cv.waitKey(1) & 0xFF #gets value of key pressed\n",
    "    if k == 27: # esc key pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    elif k == 32: # space key pressed\n",
    "        image_path = os.path.join(os.getcwd(), \"active_pic_{}.jpg\".format(image_num))\n",
    "        cv.imwrite(image_path, imgcopy)\n",
    "        print(\"saving image: active_pic_{}.jpg\".format(image_num))\n",
    "        image_num += 1\n",
    "        \n",
    "#cap.release()\n",
    "#webcamVideo.release()\n",
    "cv.destroyAllWindows()      \n",
    "\n",
    "# calculate and draw orientation/dimensions\n",
    "x_coords, y_coords = find_centroids(cntrs_t)\n",
    "angs = calculate_orientation(cntrs_e)\n",
    "calculate_dists(imgcopy, 1, cntrs_e)\n",
    "draw_features(imgcopy, cntrs_t, angs, x_coords, y_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a96e505",
   "metadata": {},
   "source": [
    "Attempting to include multi-threading/processing for concurrent live webcam feed while sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5034c4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a helper class for implementing multi-threading \n",
    "class WebcamStream :\n",
    "    # initialization method \n",
    "    def __init__(self, stream_id=0):\n",
    "        self.stream_id = stream_id # default is 0 for main camera \n",
    "        \n",
    "        # opening video capture stream \n",
    "        self.video = cv.VideoCapture(self.stream_id)\n",
    "        if self.video.isOpened() is False :\n",
    "            print(\"[Exiting]: Error accessing webcam stream.\")\n",
    "            exit(0)\n",
    "        fps_input_stream = int(self.video.get(5)) # hardware fps\n",
    "        print(\"FPS of input stream: {}\".format(fps_input_stream))\n",
    "            \n",
    "        # reading a single frame from video stream for initializing \n",
    "        self.grabbed , self.frame = self.video.read()\n",
    "        if self.grabbed is False :\n",
    "            print('[Exiting] No more frames to read')\n",
    "            exit(0)\n",
    "        # self.stopped is initialized to False \n",
    "        self.stopped = True\n",
    "        # thread instantiation  \n",
    "        self.t = Thread(target=self.update, args=())\n",
    "        self.t.daemon = True # daemon threads run in background \n",
    "        \n",
    "    # method to start thread \n",
    "    def start(self):\n",
    "        self.stopped = False\n",
    "        self.t.start()\n",
    "    # method passed to thread to read next available frame  \n",
    "    def update(self):\n",
    "        while True :\n",
    "            if self.stopped is True :\n",
    "                break\n",
    "            self.grabbed , self.frame = self.video.read()\n",
    "            if self.grabbed is False :\n",
    "                print('[Exiting] No more frames to read')\n",
    "                self.stopped = True\n",
    "                break \n",
    "        self.video.release()\n",
    "    # method to return latest read frame \n",
    "    def read(self):\n",
    "        return self.frame\n",
    "    # method to stop reading frames \n",
    "    def stop(self):\n",
    "        self.stopped = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84740adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread # library for multi-threading\n",
    "from multiprocessing import Process, Pipe\n",
    "import time\n",
    "import os  \n",
    "    \n",
    "def camera_frames(pipe, frame):\n",
    "    undist_frame = undistort_img(frame, mtx, dist) # apply camera calibration\n",
    "    imgcopy = undist_frame.copy() # copy undistorted image for any processing\n",
    "    cv.imshow(\"dist_feed\", frame) # display undistorted camera feed\n",
    "    cv.imshow(\"undist_feed\", imgcopy) # display undistorted camera feed\n",
    "    pipe.send(imgcopy)\n",
    "    \n",
    "def socket_connection(pipe, connection):\n",
    "    imgcopy = pipe.recv()\n",
    "    \n",
    "    with connection: # with a connection\n",
    "        print(f\"\\033[33m[NEW CONNECTION]\\033[0m {addr} connected.\")\n",
    "        client_message = connection.recv(Size).decode(Format) # read message to string\n",
    "        print(\"Client Message has been received: \", client_message)\n",
    "        if client_message == \"Next\":\n",
    "            print(\"Next\")\n",
    "        elif client_message == \"Stop\":\n",
    "            print(\"Stop\")\n",
    "        else: #if client_message == \"Ready\" :\n",
    "            result = inference_detector(model, imgcopy) #Run image detection\n",
    "            #print(result)\n",
    "            show_result_pyplot(model, imgcopy, result, score_thr=0.3)\n",
    "            lbl, cx, cy, width, height, theta, threshold = parse_bbox(result)\n",
    "            server_message = [str(cx), str(cy), str(theta), lbl, \"Done\"]\n",
    "            print(server_message)\n",
    "            for i in range(len(server_message)):\n",
    "                temp_str = server_message[i]\n",
    "                connection.sendto(str.encode(temp_str,Format),addr)\n",
    "                time.sleep(.25)\n",
    "            client_message = \"\"\n",
    "            time.sleep(.25)\n",
    "    connection.close()\n",
    "\n",
    "    \n",
    "cal_needed = False\n",
    "if(os.listdir(\".\\calibs\") == []):\n",
    "    cal_needed = True\n",
    "ret, mtx, dist, rvecs, tvecs = cam_cal(cal_needed) # calibrate camera\n",
    "# Start active video capture\n",
    "webcam_stream = WebcamStream(stream_id=0) # 0 id for main camera\n",
    "webcam_stream.start()\n",
    "\n",
    "# Socket Info\n",
    "client_message = \"\" # Reset client message\n",
    "print(f\"\\033[33m[Starting]\\033[0m Server is starting.\")\n",
    "server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "server.bind(ADDR)\n",
    "server.listen()\n",
    "while client_message != \"Stop\":\n",
    "    print(f\"\\033[33m[Listening]\\033[0m Server is listening.\")\n",
    "    conn, addr = server.accept() \n",
    "\n",
    "    frame = webcam_stream.read()\n",
    "    \n",
    "    parent_conn, child_conn = Pipe() \n",
    "  \n",
    "    # creating new processes \n",
    "    p1 = Process(target=camera_frames, args=(parent_conn, frame))\n",
    "    p2 = Process(target=socket_connection, args=(child_conn, conn)) \n",
    "  \n",
    "    # running process p1 and p2\n",
    "    p1.start()\n",
    "    p2.start() \n",
    "webcam_stream.stop() # stop the webcam stream\n",
    "\n",
    "webcamVideo.release()\n",
    "cv.destroyAllWindows()      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
